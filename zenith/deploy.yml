#
# Actually this does both VM provisioning and Zenith binaries deploy.
#
---

# Common tasks for both safekeepers and pageservers
- hosts: all

  tasks:

  - name: Ensure dependencies (Debian)
    apt:
      update_cache: yes
      force_apt_get: yes
      autoremove: yes
      pkg:
      - libreadline-dev
      - openssl
      - libseccomp-dev
      - gnupg
      - tmux
      # - pkg-config # rust openssl-sys needs pkg-config
      # - libclang-dev # rust rocksdb
      # - clang # rust rocksdb
    become: true

  # Requires gpg which is installed previously
  - name: Include common tasks
    import_tasks: ../common/deploy.yml

  - name: Extract Zenith binaries from zenith_install.tar.gz into /usr/local
    ansible.builtin.unarchive:
      src: zenith_install.tar.gz
      dest: /usr/local
    tags:
    - binaries
    become: true


- hosts: safekeepers

  tasks:
  - name: Import safekeepers tasks
    import_tasks: ../safekeepers/deploy.yml

  
- hosts: compute

  vars:
    pgdata_dir: /var/db/postgres/compute
    pgdata_env:
      PGDATA: /var/db/postgres/compute

  tasks:
  - name: Import compute tasks
    import_tasks: ../compute/deploy.yml


# reuse compute to deploy prometheus
- hosts: compute
  roles:
  - cloudalchemy.prometheus
  vars:
    prometheus_targets:
      node:
      # node-exporter for compute
      - targets: "{{ groups['compute']|map('extract', hostvars, ['private_ip']) | map('regex_replace', '$', ':9100') | list }}"
        labels:
          env: compute
      # node-exporter for safekeepers
      - targets: "{{ groups['safekeepers']|map('extract', hostvars, ['private_ip']) | map('regex_replace', '$', ':9100') | list }}"
        labels:
          env: safekeepers
      # safekeepers native metrics, such as LSNs
      - targets: "{{ groups['safekeepers']|map('extract', hostvars, ['private_ip']) | map('regex_replace', '$', ':7676') | list }}"
        labels:
          env: safekeepers
    prometheus_web_listen_address: "{{ private_ip }}:8080"
    prometheus_global:
      scrape_interval: 5s
      scrape_timeout: 5s
      evaluation_interval: 5s
